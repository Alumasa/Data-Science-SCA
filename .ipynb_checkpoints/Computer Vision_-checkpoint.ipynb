{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Load the data\n",
    "#2. Define a pretrained base\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "pretrained_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Attach head\n",
    "- For this example, we'll use a layer of hidden units (the first Dense layer) followed by a layer to transform the outputs to a probability score for class 1, Truck. \n",
    "- The Flatten layer transforms the two dimensional outputs of the base into the one dimensional inputs needed by the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. train \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visialize the history\n",
    "#The history object contains this information in a dictionary history.history.\n",
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before training a model in Keras, you need to specify an optimizer to perform the gradient descent, a loss function to be minimized, and (optionally) any performance metrics. \n",
    "- The optimization algorithm we'll use for this course is called \"Adam\", which generally performs well regardless of what kind of problem you're trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Classifier exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "\n",
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter with  Convolution\n",
    "- a convolution layer carries out the filtering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The weights a convnet learns during training are primarily contained in its convolutional layers. \n",
    "    - These weights we call kernels. We can represent them as small arrays.\n",
    "- A kernel operates by scanning over an image and producing a weighted sum of pixel values.\n",
    "- The kernels in a convolutional layer determine what kinds of features it creates. \n",
    "    - During training, a convnet tries to learn what features it needs to solve the classification problem. \n",
    "        - This means finding the best values for its kernels.\n",
    "- The activations in the network we call feature maps. \n",
    "    - They are what result when we apply a filter to an image; they contain the visual features the kernel extracts. \n",
    "        - With the filters parameter, you tell the convolutional layer how many feature maps you want it to create as output.\n",
    "- Detect with ReLU:\n",
    "    - A neuron with a rectifier attached is called a rectified linear unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation:\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu')\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You could think about the activation function as scoring pixel values according to some measure of importance. \n",
    "- The ReLU activation says that negative values are not important and so sets them to 0.\n",
    "    - (\"Everything unimportant is equally unimportant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Convolution and ReLU\n",
    "*Manually*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the filtering step, we'll define a kernel and then apply it with the convolution. \n",
    "#The kernel in this case is an \"edge detection\" kernel.\n",
    "import tensorflow as tf\n",
    "\n",
    "kernel = tf.constant([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1],\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "show_kernel(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat for batch compatibility.\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the kernel:\n",
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    # we'll talk about these two in lesson 4!\n",
    "    strides=1,\n",
    "    padding='SAME',\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image_filter))\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next is the detection step with the ReLU function. \n",
    "#This function is much simpler than the convolution, as it doesn't have any parameters to set.\n",
    "image_detect = tf.nn.relu(image_filter)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image_detect))\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "**filtering an image with a convolution and detecting the feature with the rectified linear unit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some standard kernels used in image processing\n",
    "import learntools.computer_vision.visiontools as visiontools\n",
    "from learntools.computer_vision.visiontools import edge, bottom_sobel, emboss, sharpen\n",
    "\n",
    "kernels = [edge, bottom_sobel, emboss, sharpen]\n",
    "names = [\"Edge Detect\", \"Bottom Sobel\", \"Emboss\", \"Sharpen\"]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, (kernel, name) in enumerate(zip(kernels, names)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    visiontools.show_kernel(kernel)\n",
    "    plt.title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional networks through mathematical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0 & 1 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 1 & 1 & 1\\\\0 & 1 & 0 & 0 & 0 & 0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "⎡0  1  0  0  0  0⎤\n",
       "⎢                ⎥\n",
       "⎢0  1  0  0  0  0⎥\n",
       "⎢                ⎥\n",
       "⎢0  1  0  0  0  0⎥\n",
       "⎢                ⎥\n",
       "⎢0  1  0  0  0  0⎥\n",
       "⎢                ⎥\n",
       "⎢0  1  0  1  1  1⎥\n",
       "⎢                ⎥\n",
       "⎣0  1  0  0  0  0⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & -1\\\\1 & -1\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "⎡1  -1⎤\n",
       "⎢     ⎥\n",
       "⎣1  -1⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-482530e3238b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msympy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Reformat for Tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Sympy is a python library for symbolic mathematics. It has a nice\n",
    "# pretty printer for matrices, which is all we'll use it for.\n",
    "import sympy\n",
    "import numpy as np\n",
    "sympy.init_printing()\n",
    "from IPython.display import display\n",
    "\n",
    "image = np.array([\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, -1],\n",
    "    [1, -1],\n",
    "])\n",
    "\n",
    "display(sympy.Matrix(image))\n",
    "display(sympy.Matrix(kernel))\n",
    "# Reformat for Tensorflow\n",
    "image = tf.cast(image, dtype=tf.float32)\n",
    "image = tf.reshape(image, [1, *image.shape, 1])\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply convolution and relu:\n",
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    strides=1,\n",
    "    padding='VALID',\n",
    ")\n",
    "image_detect = tf.nn.relu(image_filter)\n",
    "\n",
    "# The first matrix is the image after convolution, and the second is\n",
    "# the image after ReLU.\n",
    "display(sympy.Matrix(tf.squeeze(image_filter).numpy()))\n",
    "display(sympy.Matrix(tf.squeeze(image_detect).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condense with maximum pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_condense = tf.nn.pool(\n",
    "    input=image_detect, # image in the Detect step above\n",
    "    window_shape=(2, 2),\n",
    "    pooling_type='MAX',\n",
    "    # we'll see what these do in the next lesson!\n",
    "    strides=(2, 2),\n",
    "    padding='SAME',\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image_condense))\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Maximum Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translation Invariance:**\n",
    "- we talked about how maximum pooling creates translation invariance over small distances. \n",
    "- This means that we would expect small shifts to disappear after repeated maximum pooling. \n",
    "- If you run the cell multiple times, you can see the resulting image is always the same; \n",
    "    - the pooling operation destroys those small translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEATS = 4\n",
    "SIZE = [64, 64]\n",
    "\n",
    "# Create a randomly shifted circle\n",
    "image = visiontools.circle(SIZE, r_shrink=4, val=1)\n",
    "image = tf.expand_dims(image, axis=-1)\n",
    "image = visiontools.random_transform(image, jitter=3, fill_method='replicate')\n",
    "image = tf.squeeze(image)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, REPEATS+1, 1)\n",
    "plt.imshow(image, vmin=0, vmax=1)\n",
    "plt.title(\"Original\\nShape: {}x{}\".format(image.shape[0], image.shape[1]))\n",
    "plt.axis('off')\n",
    "\n",
    "# Now condense with maximum pooling several times\n",
    "for i in range(REPEATS):\n",
    "    ax = plt.subplot(1, REPEATS+1, i+2)\n",
    "    image = tf.reshape(image, [1, *image.shape, 1])\n",
    "    image = tf.nn.pool(image, window_shape=(2,2), strides=(2, 2), padding='SAME', pooling_type='MAX')\n",
    "    image = tf.squeeze(image)\n",
    "    plt.imshow(image, vmin=0, vmax=1)\n",
    "    plt.title(\"MaxPool {}\\nShape: {}x{}\".format(i+1, image.shape[0], image.shape[1]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Average Pooling\n",
    "*What is this layer doing?*\n",
    "- Notice that we no longer have the Flatten layer that usually comes after the base to transform the 2D feature data to 1D data needed by the classifier. \n",
    "- Now the GlobalAvgPool2D layer is serving this function. \n",
    "- But, instead of \"unstacking\" the feature (like Flatten), it simply replaces the entire feature map with its average value.\n",
    "    - Though very destructive, it often works quite well and has the advantage of reducing the number of parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.GlobalAvgPool2D(),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Load VGG16\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    # Attach a global average pooling layer after the base\n",
    "    layers.GlobalAvgPool2D(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "ds = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "ds_iter = iter(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GlobalAvgPool2D layer reduces each of these to a single value, an \"average pixel\", if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = next(ds_iter)\n",
    "\n",
    "car_tf = (tf.image.resize(car[0], size=[192, 192]), car[1])\n",
    "car_features = model(car_tf)\n",
    "car_features = tf.reshape(car_features, shape=(16, 32))\n",
    "label = int(tf.squeeze(car[1]).numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(tf.squeeze(car[0]))\n",
    "plt.axis('off')\n",
    "plt.title([\"Car\", \"Truck\"][label])\n",
    "plt.subplot(122)\n",
    "plt.imshow(car_features)\n",
    "plt.title('Pooled Feature Maps')\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The VGG16 base produces 512 feature maps. \n",
    "- We can think of each feature map as representing some high-level visual feature in the original image -- maybe a wheel or window. \n",
    "- Pooling a map gives us a single number, which we could think of as a score for that feature: large if the feature is present, small if it is absent. \n",
    "    - Cars tend to score high with one set of features, and Trucks score high with another. \n",
    "        - Now, instead of trying to map raw features to classes, the head only has to work with these scores that GlobalAvgPool2D produced, a much easier problem for it to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VGG16 creates 512 features maps from an image, which might represent something like a wheel or a window. \n",
    "- Each square in Pooled Feature Maps represents a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Global average pooling is often used in modern convnets. \n",
    "    - One big advantage is that it greatly reduces the number of parameters in a model, while still telling you if some feature was present in an image or not -- which for classification is usually all that matters. \n",
    "         - If you're creating a convolutional classifier it's worth trying out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
